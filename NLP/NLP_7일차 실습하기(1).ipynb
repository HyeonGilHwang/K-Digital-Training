{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_7일차 실습하기(1).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMk1buiwHpFnu98RSQE1AI3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-9BGBLpAruEu"},"source":["RNN의 문제점  \n","- 기울기 소실(지날수록 없어진다...)\n","- 번역에는 사용하기 힘들다.  \n","  각 나라별 어순정보를 파악하기 힘들다  \n","컨텍스트벡터(context vector) - Encoder은 입력문장의 모든 단어들을 순차적으로 입력받고 모든 단어를 압축한 하나의 벡터\n","\n","디코더에는 시작과 끝에 특수한 문자를 넣는다.\n","\n","어텐션 매커니즘 - 문맥을 더 잘 반영하는 벡터를 생성하는 메커니즘\n","\n","* 각 나라별 어순 정보 파악 힘들다.\n"]},{"cell_type":"markdown","metadata":{"id":"K1MNSDMKrTXt"},"source":["## Seq2seq 구현하기"]},{"cell_type":"markdown","metadata":{"id":"fIKTHhVOtqFk"},"source":["### LSTM Encoder"]},{"cell_type":"code","metadata":{"id":"bZeZ3WmkrOAX"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZhtOsPO9t1hq"},"source":["class Encoder(tf.keras.Model):\n","    '''\n","    seq2seq의 encoder\n","    '''\n","  def __init__(self, vocab_size, embedding_dim, enc_units):\n","    super(Encoder, self).__init__()\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.lstm = tf.keras.layers.LSTM(enc_units)\n","    # return_sequences 매개변수를 기본값 False로 전달\n","\n","  def call(self, x): # __call__ 과 비슷한 듯\n","\n","    print(\"입력 shape:\",x.shape)\n","    \n","    x=self.embedding(x)\n","    print(\"Embedding Layer를 거친 shape \", x.shape)\n","\n","    output = self.lstm(x)\n","    print(\"LSTM Layer의 Output Shape :\", output.shape)\n","\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E_9VaTc9u6Pg","executionInfo":{"status":"ok","timestamp":1623979885386,"user_tz":-540,"elapsed":236,"user":{"displayName":"Hyeongil Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJw9-6FPBKewJEnrTAuyTD41wiop2u60rHxHe8=s64","userId":"03191511579693962069"}},"outputId":"2ec3f793-6678-4bf2-a866-c9a7c906068c"},"source":["vocab_size = 30000\n","emd_size = 256\n","lstm_size = 512\n","batch_size = 1\n","sample_seq_len = 3\n","\n","print(\"Vocab Size : {0}\".format(vocab_size))\n","print(\"Embedding Size : {0}\".format(emd_size))\n","print(\"LSTM Size : {0}\".format(lstm_size))\n","print(\"Batch Size : {0}\".format(batch_size))\n","print(\"Sample Sequence Length {0}\\n\".format(sample_seq_len))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Vocab Size : 30000\n","Embedding Size : 256\n","LSTM Size : 512\n","Batch Size : 1\n","Sample Sequence Length 3\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wgWHOiyKvjV1","executionInfo":{"status":"ok","timestamp":1623979977780,"user_tz":-540,"elapsed":3562,"user":{"displayName":"Hyeongil Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJw9-6FPBKewJEnrTAuyTD41wiop2u60rHxHe8=s64","userId":"03191511579693962069"}},"outputId":"fe8251ee-4a9e-4030-a569-63bbf22ede92"},"source":["encoder = Encoder(vocab_size, emb_size, lstm_size)\n","sample_input = tf.zeros((batch_size, sample_seq_len))\n","\n","sample_output = encoder(sample_input)\n","# 컨텍스트 벡터로 사용한 인코더 LSTM의 최종 State값"],"execution_count":null,"outputs":[{"output_type":"stream","text":["입력 shape: (1, 3)\n","Embedding Layer를 거친 shape  (1, 3, 256)\n","LSTM Layer의 Output Shape : (1, 512)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QcvONqEOwCy3"},"source":["![](https://aiffelstaticprd.blob.core.windows.net/media/images/GN-4-L-6.max-800x600.jpg)"]},{"cell_type":"markdown","metadata":{"id":"oNrbLEkewQ1D"},"source":["### LSTM Decoder"]},{"cell_type":"code","metadata":{"id":"uljw1efJv5kS"},"source":["class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, dec_units):\n","    super(Decoder, self).__init__()\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.lstm = tf.keras.layers.LSTM(dec_units, return_sequences=True)\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","    self.softmax = tf.keras.layers.Softmax(axis= -1)\n","\n","  def call(self, x, context_v):\n","    # 디코더의 입력 x와 인코더의 컨텍스트 벡터를 인자로 받습니다.\n","    print(\"입력 shape :\", x.shape)\n","\n","    x = self.embedding(x)\n","    print(\"Embedding Layer를 거친 Shape:\", x.shape)\n","\n","    context_v = tf.repeat(tf.expand_dims(context_v, axis=1), repeats=x.shape[1], axis =1)\n","    x = tf.concat([x, context_v], axis = -1)\n","    print(\"Context Vector가 더해진 Shape :\", x.shape)\n","\n","    x = self.lstm(x)\n","    print(\"LSTM Layer의 Output Shape :\", x.shape)\n","\n","    output = self.fc(x)\n","    print(\"Decoder 최종 Output Shape :\", output.shape)\n","\n","    return self.softmax(output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xpFsFjv-yAJP","executionInfo":{"status":"ok","timestamp":1623980619248,"user_tz":-540,"elapsed":285,"user":{"displayName":"Hyeongil Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJw9-6FPBKewJEnrTAuyTD41wiop2u60rHxHe8=s64","userId":"03191511579693962069"}},"outputId":"2b718d63-f5ae-4d2d-ea7e-d7f257f465aa"},"source":["print(\"vocab Size : {0}\".format(vocab_size))\n","print(\"Embedding Size : {0}\".format(emb_size))\n","print(\"LSTM Size : {0}\".format(lstm_size))\n","print(\"Batch Size : {0}\".format(batch_size))\n","print(\"Sample Sequence Length : {0}\\n\".format(sample_seq_len))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["vocab Size : 30000\n","Embedding Size : 256\n","LSTM Size : 512\n","Batch Size : 1\n","Sample Sequence Length : 3\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a15-njXzyaD9","executionInfo":{"status":"ok","timestamp":1623980734738,"user_tz":-540,"elapsed":2921,"user":{"displayName":"Hyeongil Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJw9-6FPBKewJEnrTAuyTD41wiop2u60rHxHe8=s64","userId":"03191511579693962069"}},"outputId":"e6c5ac90-8f2f-4776-f286-37328e773ec6"},"source":["decoder = Decoder(vocab_size, emb_size, lstm_size)\n","sample_input = tf.zeros((batch_size, sample_seq_len))\n","\n","dec_output = decoder(sample_input, sample_output)\n","# Decoder, call(x, context_v)를 호출"],"execution_count":null,"outputs":[{"output_type":"stream","text":["입력 shape : (1, 3)\n","Embedding Layer를 거친 Shape: (1, 3, 256)\n","Context Vector가 더해진 Shape : (1, 3, 768)\n","LSTM Layer의 Output Shape : (1, 3, 512)\n","Decoder 최종 Output Shape : (1, 3, 30000)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PdfqKMSGy8NE"},"source":["![](https://aiffelstaticprd.blob.core.windows.net/media/images/GN-4-L-7.max-800x600.jpg)"]},{"cell_type":"markdown","metadata":{"id":"5BKqkmyG5DFV"},"source":["Rnn에 기반한 seq2seq 모델 두가지 문제점\n","1. 기억소실  \n","2. 하나의 고정된 벡터에 모든 정보를 압축하려다 보니 정보 손실이 발생"]},{"cell_type":"markdown","metadata":{"id":"qDISWyH75XDr"},"source":["## 어텐션 메커니즘(Attention Mechanism)"]},{"cell_type":"markdown","metadata":{"id":"huZJ7P-P5mfV"},"source":["- 어텐션의 아이디어는 디코더에서 출력 단어를 예측하는 매시점(time step)마다 인코더에서의 전체 입력 문장을 다시 한 번 참고한다는 점\n","- 전체 입력 문장을 전부 다 동일한 비율로 참고하는 것이 아니라, 해당 시점에서 예측해야할 단어와 연관이 있는 입력 단어부분을 좀 더 집주해서 보자."]},{"cell_type":"code","metadata":{"id":"fcqTIt6cysmw"},"source":["dict = {\"2017\" : \"Transformer\", \"2018\" : \"BERT\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3BfT0q16CeB","executionInfo":{"status":"ok","timestamp":1623982628128,"user_tz":-540,"elapsed":255,"user":{"displayName":"Hyeongil Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJw9-6FPBKewJEnrTAuyTD41wiop2u60rHxHe8=s64","userId":"03191511579693962069"}},"outputId":"936335af-d87d-40b3-c508-ec0573e2b141"},"source":["print(dict[\"2017\"])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Transformer\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xcl0tGbX6DnD","executionInfo":{"status":"ok","timestamp":1623982642658,"user_tz":-540,"elapsed":233,"user":{"displayName":"Hyeongil Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJw9-6FPBKewJEnrTAuyTD41wiop2u60rHxHe8=s64","userId":"03191511579693962069"}},"outputId":"03f1806d-5f1f-46ed-d0d5-25fa1d38aa14"},"source":["print(dict[\"2018\"])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["BERT\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tlLzo5Mo6dwG"},"source":["![](https://wikidocs.net/images/page/22893/%EC%BF%BC%EB%A6%AC.PNG)"]},{"cell_type":"markdown","metadata":{"id":"GL8Yzhoi6f30"},"source":["Attention(Q, K, V) = Attention Value"]},{"cell_type":"markdown","metadata":{"id":"zbn_VGWK6h-e"},"source":["- Query : t 시점의 디코더 셀에서의 은닉 상태\n","- Key : 모든 시점의 인코더 셀의 은닉 상태\n","- Value : 모든 시점의 인코더 셀의 은닉 상태"]},{"cell_type":"markdown","metadata":{"id":"x68jHYN8652s"},"source":["### 닷 프로덕트 어텐션 (Dot-Product Attention)"]},{"cell_type":"markdown","metadata":{"id":"qSgAK0vR7G7F"},"source":["![](https://wikidocs.net/images/page/22893/dotproductattention1_final.PNG)"]},{"cell_type":"markdown","metadata":{"id":"QgzRDfFl7icL"},"source":["### 1. 어텐션 스코어 구하기"]},{"cell_type":"markdown","metadata":{"id":"qPkGTfw77q4t"},"source":["![](https://wikidocs.net/images/page/22893/dotproductattention2_final.PNG)"]},{"cell_type":"markdown","metadata":{"id":"b9nF9_1s8yNB"},"source":["$$score(s_t, h_i) = S_t^T h_i $$"]},{"cell_type":"markdown","metadata":{"id":"eJ3yM2Hz8_aW"},"source":["$$e^t = [s_t^T h_1, ..., s_t^T h_N]$$"]},{"cell_type":"markdown","metadata":{"id":"1m0zTACx8Y0I"},"source":["### 2. 소프트맥스(softmax)함수를 통해 어텐션 분포를 구함"]},{"cell_type":"markdown","metadata":{"id":"zHecKeO68kZl"},"source":["![](https://wikidocs.net/images/page/22893/dotproductattention3_final.PNG)"]},{"cell_type":"markdown","metadata":{"id":"DDeht0WT9FRr"},"source":["$$a^t = softmax(e^t)$$"]},{"cell_type":"markdown","metadata":{"id":"9pTm7Hno8eZV"},"source":["### 3. 각 인코더의 어텐션 가중치와 은닉 상태를 가중합하여 어텐션 값을 구함"]},{"cell_type":"markdown","metadata":{"id":"qZNozhGU86el"},"source":["![](https://wikidocs.net/images/page/22893/dotproductattention4_final.PNG)"]},{"cell_type":"markdown","metadata":{"id":"GJTh5ytM9HiD"},"source":["$$a_t = \\sum_{i=1}^{N}{a_i^th_i}$$ "]},{"cell_type":"markdown","metadata":{"id":"Sbmm6LEG9cIG"},"source":["### 4. 어텐션 값과 디코더의 t 시점의 은닉 상태를 연결한다.(Concatenate)"]},{"cell_type":"markdown","metadata":{"id":"p065YnWm9kRM"},"source":["![](https://wikidocs.net/images/page/22893/dotproductattention5_final_final.PNG)"]},{"cell_type":"markdown","metadata":{"id":"4OxgjhvO95U6"},"source":["### 5. 출력층 연산의 입력이 되는 st를 계산"]},{"cell_type":"markdown","metadata":{"id":"rKpNOih_9_Ag"},"source":["![](https://wikidocs.net/images/page/22893/st.PNG)"]},{"cell_type":"markdown","metadata":{"id":"AwgYfiCh-HKX"},"source":["$$ \\tilde{s_{t}}=tanh(W_c[a_t ; s_t] + b_c)$$"]},{"cell_type":"markdown","metadata":{"id":"CIFDglJZ-tYO"},"source":["### 6. st를 출력층의 입력으로 사용"]},{"cell_type":"markdown","metadata":{"id":"IQSVlaBQ-1Dc"},"source":["$$ \\hat{y_t}=Softmax(W_y\\tilde{s_t}+b_y)$$"]},{"cell_type":"markdown","metadata":{"id":"N-eT1Ue7AcnI"},"source":["- Bahdanau Attention\n","$$ Score_{alignment} = W * tanh(W_{decoder}* H_{decoder} +W_{encoder}* H_{encoder}) $$"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SmVQ98oi-Gmw","executionInfo":{"status":"ok","timestamp":1623984992792,"user_tz":-540,"elapsed":245,"user":{"displayName":"Hyeongil Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJw9-6FPBKewJEnrTAuyTD41wiop2u60rHxHe8=s64","userId":"03191511579693962069"}},"outputId":"d63429e8-68b9-4af5-ae05-2c14ddea7588"},"source":["class BahdanauAttention(tf.keras.layers.Layer):\n","  def __init__(self, units):\n","    super(BahdanauAttention, self).__init__()\n","    self.W_decoder = tf.keras.layers.Dense(units)\n","    self.W_encoder = tf.keras.layers.Dense(units)\n","    self.W_combine = tf.keras.layers.Dense(1)\n","\n","  def call(self, H_encoder, H_decoder):\n","    print(\"[H_encoder] Shape :\", H_encoder.shape)\n","\n","    H_encoder = self.W_encoder(H_encoder)\n","    print(\"[W_encoder X H_encoder] Shape:\", H_encoder.shape)\n","\n","    print(\"\\n[H_decoder] Shape: \", H_decoder.shape)\n","    H_decoder = tf.expand_dims(H_decoder, 1)\n","    H_decoder = self.W_decoder(H_decoder)\n","\n","    print(\"[W_decoder X H_decoder] Shape:\", H_decoder.shape)\n","\n","    score = self.W_combine(tf.nn.tanh(H_decoder+H_encoder))\n","    print(\"[Score_alignment]Shape :\", score.shape)\n","\n","    attention_weights = tf.nn.softmax(score, axis = 1)\n","    print(\"\\n최종 weight : \\n\", attention_weights.numpy())\n","\n","    context_vector = attention_weights * H_decoder\n","    context_vector = tf.reduce_sum(context_vector, axis = 1)\n","\n","    return context_vector, attention_weights\n","\n","W_size = 100\n","\n","print(\"Hidden State를 {0}차원으로 Mapping\\n\".format(W_size))\n","\n","attention = BahdanauAttention(W_size)\n","\n","enc_state = tf.random.uniform((1, 10, 512))\n","dec_state = tf.random.uniform((1, 512))\n","\n","_ = attention(enc_state, dec_state)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Hidden State를 100차원으로 Mapping\n","\n","[H_encoder] Shape : (1, 10, 512)\n","[W_encoder X H_encoder] Shape: (1, 10, 100)\n","\n","[H_decoder] Shape:  (1, 512)\n","[W_decoder X H_decoder] Shape: (1, 1, 100)\n","[Score_alignment]Shape : (1, 10, 1)\n","\n","최종 weight : \n"," [[[0.07261766]\n","  [0.10911326]\n","  [0.06998613]\n","  [0.1168275 ]\n","  [0.08299869]\n","  [0.09790228]\n","  [0.10768744]\n","  [0.14077783]\n","  [0.10282373]\n","  [0.09926549]]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ugxgMSmLDEi2"},"source":["![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/GN-4-L-9.jpg)"]},{"cell_type":"markdown","metadata":{"id":"iNIoGazFDjKV"},"source":["### Loung Attention"]},{"cell_type":"markdown","metadata":{"id":"QrNxr35cDlpG"},"source":["$$ Score(H_{target},H_{source}) = H_{target}^T * W_{combine} * H_{source} $$"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oi-AwxOo6JOU","executionInfo":{"status":"ok","timestamp":1623985554379,"user_tz":-540,"elapsed":257,"user":{"displayName":"Hyeongil Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJw9-6FPBKewJEnrTAuyTD41wiop2u60rHxHe8=s64","userId":"03191511579693962069"}},"outputId":"3b150706-2764-4bd2-bf8b-bc38ba502753"},"source":["class LuongAttention(tf.keras.layers.Layer):\n","  def __init__(self, units):\n","    super(LuongAttention, self).__init__()\n","    self.W_combine = tf.keras.layers.Dense(units)\n","  \n","  def call(self, H_encoder, H_decoder):\n","    print(\"[H_encoder] shape: \", H_encoder.shape)\n","\n","    WH = self.W_combine(H_encoder)\n","    print(\"[W_encoder X H_encoder] shape :\", WH.shape)\n","\n","    H_decoder = tf.expand_dims(H_decoder, 1)\n","    alignment = tf.matmul(WH, tf.transpose(H_decoder, [0, 2, 1]))\n","    print(\"[Score_alignment] Shape :\", alignment.shape)\n","\n","    attention_weights = tf.nn.softmax(alignment, axis = 1)\n","    print(\"\\n최종 weight : \\n\", attention_weights.numpy())\n","\n","    attention_weights = tf.squeeze(attention_weights, axis = -1)\n","    context_vector = tf.matmul(attention_weights, H_encoder)\n","\n","    return context_vector, attention_weights\n","\n","emb_dim = 512\n","\n","attention = LuongAttention(emb_dim)\n","\n","enc_state = tf.random.uniform((1, 10, emb_dim))\n","dec_state = tf.random.uniform((1, emb_dim))\n","\n","_ = attention(enc_state, dec_state)\n","\n","## 최종 weight의 크기는 단어연산의 크기와 동일하게 가능 여기선 \"10\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["[H_encoder] shape:  (1, 10, 512)\n","[W_encoder X H_encoder] shape : (1, 10, 512)\n","[Score_alignment] Shape : (1, 10, 1)\n","\n","최종 weight : \n"," [[[4.45325812e-03]\n","  [7.42507109e-05]\n","  [3.36647296e-04]\n","  [2.15690989e-06]\n","  [4.97238189e-01]\n","  [1.21852165e-04]\n","  [6.61878512e-05]\n","  [2.27045442e-04]\n","  [4.97472733e-01]\n","  [7.71726900e-06]]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vyNcCGPXgrwm"},"source":["## 양방향 LSTM과 어텐션 메커니즘 (IMDB리뷰데이터)"]},{"cell_type":"markdown","metadata":{"id":"xRjC0vJ3gyx_"},"source":["### IMDB 리뷰 데이터 전처리하기"]},{"cell_type":"code","metadata":{"id":"62dkh48-648r"},"source":["from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mIbdSwYjhSu3","executionInfo":{"status":"ok","timestamp":1623995677350,"user_tz":-540,"elapsed":36901,"user":{"displayName":"Hyeongil Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJw9-6FPBKewJEnrTAuyTD41wiop2u60rHxHe8=s64","userId":"03191511579693962069"}},"outputId":"bc22f148-cbbf-46e9-de2f-84efa3f3f349"},"source":["vocab_size = 10000\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = vocab_size)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ajcWdikFhkyl","executionInfo":{"status":"ok","timestamp":1623995677352,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hyeongil Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJw9-6FPBKewJEnrTAuyTD41wiop2u60rHxHe8=s64","userId":"03191511579693962069"}},"outputId":"0e783912-93c6-4dc4-f2fc-59d954762936"},"source":["# 정수 인코딩이 되어 있어 패딩바로 시작\n","print('리뷰의 최대 길이 : {}'.format(max(len(l) for l in x_train)))\n","print('리뷰의 평균 길이 : {}'.format(sum(map(len, x_train))/len(x_train)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["리뷰의 최대 길이 : 2494\n","리뷰의 평균 길이 : 238.71364\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-aZ1ntcriQMS"},"source":["max_len = 500\n","x_train = pad_sequences(x_train, maxlen=max_len)\n","x_test = pad_sequences(x_test, maxlen=max_len)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hHDOozMiibaY"},"source":["### 바다나우 어텐션"]},{"cell_type":"markdown","metadata":{"id":"Bep1H5I_ihQl"},"source":["$$score(query, key) = V^Ttanh(W_1 key + W_2 query)$$"]},{"cell_type":"code","metadata":{"id":"h-Xg1O4WiaKO"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JaizYBMciyR0"},"source":["class BahdanauAttention(tf.keras.Model):\n","  def __init__(self, units):\n","    super(BahdanauAttention, self).__init__()\n","    self.W1 = Dense(units)\n","    self.W2 = Dense(units)\n","    self.V = Dense(1)\n","\n","  def call(self, values, query): \n","    #query size (batch_size, hidden size)\n","    # hidde_with time axis shape (batch size, 1, hidden_size)\n","    hidden_with_time_axis = tf.expand_dims(query, 1)\n","\n","    # score shape == (batch_size, max_length, 1)\n","    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n","\n","    # attention weights shape == (batch size, max_length, 1)\n","    attention_weights = tf.nn.softmax(score, axis =1 )\n","\n","    # context_vector shape after sum == (batch size, hidden size)\n","    context_vector = attention_weights * values\n","    context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","    return context_vector, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zjNTZQ_-kD0t"},"source":["### 양방향 LSTM + 어텐션 메커니즘"]},{"cell_type":"code","metadata":{"id":"sBNGXrIekCsD"},"source":["from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n","from tensorflow.keras import Input, Model\n","from tensorflow.keras import optimizers\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xbgwY9A7kXbl"},"source":["sequence_input = Input(shape =(max_len, ), dtype='int32')\n","embedded_sequences = Embedding(vocab_size, 128, input_length=max_len, mask_zero = True)(sequence_input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MAX-XuD7kqbR"},"source":["# dropout - 0.5 -> 노드와 노드 사이의 가중치를 50% 날려버림.. 오버피팃 방지\n","lstm = Bidirectional(LSTM(64, dropout=0.5, return_sequences=True))(embedded_sequences)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b0zSHipYlIiF"},"source":["lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h-Kfb3H8lKmG","executionInfo":{"status":"ok","timestamp":1623995688679,"user_tz":-540,"elapsed":17,"user":{"displayName":"Hyeongil Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJw9-6FPBKewJEnrTAuyTD41wiop2u60rHxHe8=s64","userId":"03191511579693962069"}},"outputId":"36c1035f-5035-44cb-ce75-5fe2fc7d1ef0"},"source":["print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(None, 500, 128) (None, 64) (None, 64) (None, 64) (None, 64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AtHPFspolMtA"},"source":["state_h = Concatenate()([forward_h, backward_h])# 은닉 상태\n","state_c = Concatenate()([forward_c, backward_c])# 셀 상태"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RYkgTksGlcK3"},"source":["attention = BahdanauAttention(64) # 가중치의 크기 정의\n","context_vector, attention_weights = attention(lstm, state_h)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Netd85zRlnOG"},"source":["dense1 = Dense(20, activation='relu')(context_vector)# sigmoid 안씀 왜?? 히든이어서\n","dropout = Dropout(0.5)(dense1)\n","output = Dense(1,activation=\"sigmoid\")(dropout)# 여기서 출력에서만 sigmoid 쓸지 고려\n","model = Model(inputs=sequence_input, outputs = output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2aI-bNcumhPt"},"source":["model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S2s42w8gmzXW","executionInfo":{"status":"ok","timestamp":1623998121697,"user_tz":-540,"elapsed":2433026,"user":{"displayName":"Hyeongil Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJw9-6FPBKewJEnrTAuyTD41wiop2u60rHxHe8=s64","userId":"03191511579693962069"}},"outputId":"5841c508-7b35-442e-849b-de68a65cbb36"},"source":["history = model.fit(x_train, y_train, epochs=5, batch_size=256, validation_data=(x_test, y_test), verbose = 1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","98/98 [==============================] - 497s 5s/step - loss: 0.4590 - accuracy: 0.7807 - val_loss: 0.2818 - val_accuracy: 0.8836\n","Epoch 2/5\n","98/98 [==============================] - 477s 5s/step - loss: 0.2459 - accuracy: 0.9099 - val_loss: 0.2820 - val_accuracy: 0.8833\n","Epoch 3/5\n","98/98 [==============================] - 477s 5s/step - loss: 0.1953 - accuracy: 0.9352 - val_loss: 0.3199 - val_accuracy: 0.8803\n","Epoch 4/5\n","98/98 [==============================] - 474s 5s/step - loss: 0.1613 - accuracy: 0.9484 - val_loss: 0.3495 - val_accuracy: 0.8763\n","Epoch 5/5\n","98/98 [==============================] - 473s 5s/step - loss: 0.1339 - accuracy: 0.9574 - val_loss: 0.4018 - val_accuracy: 0.8702\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3cl15GwCm1BN","executionInfo":{"status":"ok","timestamp":1623998513693,"user_tz":-540,"elapsed":382192,"user":{"displayName":"Hyeongil Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJw9-6FPBKewJEnrTAuyTD41wiop2u60rHxHe8=s64","userId":"03191511579693962069"}},"outputId":"a300b35f-8382-4c79-ca1c-3bc7715c79cc"},"source":["print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(x_test, y_test)[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["782/782 [==============================] - 338s 432ms/step - loss: 0.4018 - accuracy: 0.8702\n","\n"," 테스트 정확도: 0.8702\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jxmK7rgT7RVK"},"source":["**---->> 여기서부터 갑자기 에러 발생 NLP_7일차 실습하기(2)로 이동**"]},{"cell_type":"markdown","metadata":{"id":"qCauBLZI2jqD"},"source":["## seq2seq with attention 스페인-영어 번역기"]},{"cell_type":"markdown","metadata":{"id":"n5zuT8RR56Xq"},"source":["### 데이터 준비하기"]},{"cell_type":"code","metadata":{"id":"b9qu8nmp1Otg","executionInfo":{"status":"ok","timestamp":1623999648283,"user_tz":-540,"elapsed":256,"user":{"displayName":"Hyeongil Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJw9-6FPBKewJEnrTAuyTD41wiop2u60rHxHe8=s64","userId":"03191511579693962069"}}},"source":["import tensorflow as tf\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","\n","import matplotlib.ticker as ticker\n","import matplotlib.pyplot as plt\n","\n","import time\n","import re\n","import os\n","import io"],"execution_count":83,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":324},"id":"R0mE6IX15InI","executionInfo":{"status":"error","timestamp":1623999653519,"user_tz":-540,"elapsed":318,"user":{"displayName":"Hyeongil Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJw9-6FPBKewJEnrTAuyTD41wiop2u60rHxHe8=s64","userId":"03191511579693962069"}},"outputId":"ce1985d3-b54b-4144-de43-80501238a8cb"},"source":["path_to_zip = tf.keras.utils.get_file('spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip', extract=True)"],"execution_count":84,"outputs":[{"output_type":"error","ename":"FileExistsError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-84-15e0a8c8f806>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath_to_zip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spa-eng.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0m_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36m_extract_archive\u001b[0;34m(file_path, path, archive_format)\u001b[0m\n\u001b[1;32m    134\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m           \u001b[0marchive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTarError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1636\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmember\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1686\u001b[0;31m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1687\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/root/.keras/datasets/spa-eng'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"f8OO9wh05YK2","executionInfo":{"status":"error","timestamp":1623999500448,"user_tz":-540,"elapsed":287,"user":{"displayName":"Hyeongil Hwang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJw9-6FPBKewJEnrTAuyTD41wiop2u60rHxHe8=s64","userId":"03191511579693962069"}},"outputId":"f5a18b61-4de2-4d7f-8a94-fab9c6c1fb1b"},"source":["path_to_file = os.path.dirname(path_to_zip)+ \"/spa-eng/spa.txt\""],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-82-2e46d7519edc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath_to_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_zip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m\"/spa-eng/spa.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'path_to_zip' is not defined"]}]},{"cell_type":"code","metadata":{"id":"t4L6W4qF6d2v"},"source":["with open(path_to_file, \"r\") as f:\n","  raw = f.read().splitlines()\n","\n","print(\"Data Size: \", len(raw))\n","print(\"Example:\")\n","\n","for sen in raw[0:100][::20]: print(\">>\", sen)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0sx0mFD06iG-"},"source":["### 데이터 전처리 : 정제하기"]},{"cell_type":"code","metadata":{"id":"q1AfFstZ6gB1"},"source":[""],"execution_count":null,"outputs":[]}]}