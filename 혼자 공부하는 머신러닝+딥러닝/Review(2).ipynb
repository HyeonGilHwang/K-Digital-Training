{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Species  Weight  Length  Diagonal   Height   Width\n",
      "0   Bream   242.0    25.4      30.0  11.5200  4.0200\n",
      "1   Bream   290.0    26.3      31.2  12.4800  4.3056\n",
      "2   Bream   340.0    26.5      31.1  12.3778  4.6961\n",
      "3   Bream   363.0    29.0      33.5  12.7300  4.4555\n",
      "4   Bream   430.0    29.0      34.0  12.4440  5.1340\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fish = pd.read_csv('https://bit.ly/fish_csv')\n",
    "print(fish.head())\n",
    "\n",
    "# print(type(fish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_input = fish[['Weight','Length','Diagonal','Height','Width']].to_numpy()\n",
    "\n",
    "fish_target = fish['Species'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream',\n",
       "       'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream',\n",
       "       'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream',\n",
       "       'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream',\n",
       "       'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream',\n",
       "       'Roach', 'Roach', 'Roach', 'Roach', 'Roach', 'Roach', 'Roach',\n",
       "       'Roach', 'Roach', 'Roach', 'Roach', 'Roach', 'Roach', 'Roach',\n",
       "       'Roach', 'Roach', 'Roach', 'Roach', 'Roach', 'Roach', 'Whitefish',\n",
       "       'Whitefish', 'Whitefish', 'Whitefish', 'Whitefish', 'Whitefish',\n",
       "       'Parkki', 'Parkki', 'Parkki', 'Parkki', 'Parkki', 'Parkki',\n",
       "       'Parkki', 'Parkki', 'Parkki', 'Parkki', 'Parkki', 'Perch', 'Perch',\n",
       "       'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch',\n",
       "       'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch',\n",
       "       'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch',\n",
       "       'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch',\n",
       "       'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch',\n",
       "       'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch',\n",
       "       'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch',\n",
       "       'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Pike', 'Pike',\n",
       "       'Pike', 'Pike', 'Pike', 'Pike', 'Pike', 'Pike', 'Pike', 'Pike',\n",
       "       'Pike', 'Pike', 'Pike', 'Pike', 'Pike', 'Pike', 'Pike', 'Smelt',\n",
       "       'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt',\n",
       "       'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    fish_input, fish_target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "#Compute the mean and std to be used for later scaling.\n",
    "## scaling 안하는 경우 -> 분류가 아닌 예측의 경우, tree\n",
    "\n",
    "ss.fit(train_input)\n",
    "\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8067226890756303\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_scaled, train_target)\n",
    "\n",
    "print(lr.score(train_scaled, train_target))\n",
    "print(lr.score(test_scaled, test_target))\n",
    "\n",
    "# lr = LogisticRegression(penalty='l2', C=20, max_iter=1000) \n",
    "# lr.fit(train_scaled, train_target)\n",
    "\n",
    "# print(lr.score(train_scaled, train_target))\n",
    "# print(lr.score(test_scaled, test_target))\n",
    "# LogisticRegression(\n",
    "#     penalty='l2', l2 - 리지, l1-라소\n",
    "#     *,\n",
    "#     dual=False,\n",
    "#     tol=0.0001,\n",
    "#     C=1.0, # 1 / lambda \n",
    "#     fit_intercept=True,\n",
    "#     intercept_scaling=1,\n",
    "#     class_weight=None,\n",
    "#     random_state=None,\n",
    "#     solver='lbfgs',\n",
    "#     max_iter=100,\n",
    "#     multi_class='auto',\n",
    "#     verbose=0,\n",
    "#     warm_start=False,\n",
    "#     n_jobs=None,\n",
    "#     l1_ratio=None,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Perch' 'Smelt' 'Pike' 'Perch' 'Perch']\n"
     ]
    }
   ],
   "source": [
    "print(lr.predict(test_scaled[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.004 0.092 0.545 0.008 0.281 0.061 0.01 ]\n",
      " [0.    0.061 0.126 0.002 0.087 0.722 0.001]\n",
      " [0.009 0.009 0.223 0.569 0.17  0.006 0.013]\n",
      " [0.061 0.077 0.526 0.036 0.257 0.003 0.04 ]\n",
      " [0.004 0.03  0.664 0.026 0.245 0.018 0.013]]\n"
     ]
    }
   ],
   "source": [
    "proba = lr.predict_proba(test_scaled[:5])\n",
    "print(np.round(proba, decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.48635407e-01 -8.16338300e-02  6.40677025e-01  2.81886254e+00\n",
      "  -3.23791215e-01]\n",
      " [-3.35559709e-01 -8.21454187e-01 -8.35625183e-01  1.91834624e+00\n",
      "  -8.55673174e-01]\n",
      " [ 1.30777936e+00  3.20627792e-01 -1.31830404e+00 -1.71471286e+00\n",
      "   1.64054397e+00]\n",
      " [ 1.33816721e-03  1.72779398e+00  1.75766272e+00 -1.28638162e+00\n",
      "  -6.35345781e-01]\n",
      " [-8.14258430e-01 -5.24809489e-01  3.53859503e-01 -4.21963234e-01\n",
      "   6.26572878e-01]\n",
      " [-3.55031912e-01 -6.41091506e-01 -6.57484132e-01 -1.46560568e+00\n",
      "  -1.51685481e+00]\n",
      " [ 3.44367925e-01  2.05672435e-02  5.92141133e-02  1.51454608e-01\n",
      "   1.06454813e+00]] [ 0.38862776 -0.11439729  2.40795555  0.04859162  1.15910169 -3.78185807\n",
      " -0.10802126]\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_, lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9663865546218487\n",
      "0.925\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty = 'l1', C=20, max_iter=1000, solver='liblinear')\n",
    "\n",
    "lr.fit(train_scaled, train_target)\n",
    "\n",
    "print(lr.score(train_scaled, train_target))\n",
    "print(lr.score(test_scaled, test_target))\n",
    "\n",
    "# ‘newton-cg’, ‘lbfgs’, ‘sag’ and ‘saga’ handle L2 or no penalty\n",
    "# ‘liblinear’ and ‘saga’ also handle L1 penalty\n",
    "# ‘saga’ also supports ‘elasticnet’ penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -7.35612412   0.           5.05871523  13.06733515   0.        ]\n",
      " [ -8.02115711  16.39537748 -29.93026455  14.7343097    0.        ]\n",
      " [ -2.43369577  73.81209548 -78.79714514   2.13597649   4.38225903]\n",
      " [  0.           0.           9.62590673  -4.61068527  -3.87766674]\n",
      " [ -9.30730354 -42.41828314  39.7947627   -5.15651097   9.42156067]\n",
      " [ -7.53579924   0.           7.73250297  -9.24411999  -5.28487516]\n",
      " [ -1.98242966  -1.45137452   0.           0.           3.71523595]] [-10.06125985 -12.79755565  -4.00677415  -6.03449221  -6.64651241\n",
      " -18.14411876  -4.60790092]\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_, lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(lr.coef_ == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
